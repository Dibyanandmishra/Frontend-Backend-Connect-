{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#@title Install and Auto restart\n",
        "requirements_content = \"\"\"accelerate==0.25.0\n",
        "huggingface-hub==0.20.1\n",
        "Pillow==10.1.0\n",
        "transformers==4.36.2\n",
        "einops==0.7.0\n",
        "gradio==4.15.0\n",
        "timm==0.9.12\n",
        "pydub==0.25.1\n",
        "edge-tts\n",
        "#torch==2.1.2\n",
        "#torchvision==0.16.2\n",
        "\"\"\"\n",
        "# Write the contents to the file\n",
        "with open(\"/content/requirements.txt\", \"w\") as file:\n",
        "    file.write(requirements_content)\n",
        "\n",
        "print(f\"File '/content/requirements.txt' has been successfully created with the specified contents.\")\n",
        "\n",
        "# from google.colab import output\n",
        "# output.eval_js('new Audio(\"https://github.com/neuralfalcon/Roop-Image-FaceSwap/raw/main/start.mp3\").play()')\n",
        "!pip install -r /content/requirements.txt\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "# output.eval_js('new Audio(\"https://github.com/neuralfalcon/Roop-Image-FaceSwap/raw/main/install_voice.mp3\").play()')\n",
        "import time\n",
        "time.sleep(6)\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "eY94buNbkEId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <-- Play the audio { display-mode: \"form\" }\n",
        "\n",
        "# !git clone https://github.com/vikhyat/moondream.git\n",
        "# %cd /content/moondream\n",
        "# from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "# from PIL import Image\n",
        "\n",
        "# model_id = \"vikhyatk/moondream2\"\n",
        "# revision = \"2024-03-13\"\n",
        "# model = AutoModelForCausalLM.from_pretrained(\n",
        "#     model_id, trust_remote_code=True, revision=revision\n",
        "# )\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_id, revision=revision)\n",
        "# from PIL import Image\n",
        "# image = Image.open('/content/monalisa.jpg')\n",
        "# image = Image.open('/content/monalisa.jpg')\n",
        "# enc_image = model.encode_image(image)\n",
        "# print(model.answer_question(enc_image, \"Describe this image.\", tokenizer))\n",
        "%%html\n",
        "<b>Press play on the music player to keep the tab alive, then run the cell below</b><br/>\n",
        "<audio src=\"https://raw.githubusercontent.com/KoboldAI/KoboldAI-Client/main/colab/silence.m4a\" controls>"
      ],
      "metadata": {
        "id": "TtcASW2W4prb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <-- Just run the cell (config edge TTS)\n",
        "def calculate_rate_string(input_value):\n",
        "    rate = (input_value - 1) * 100\n",
        "    sign = '+' if input_value >= 1 else '-'\n",
        "    return f\"{sign}{abs(int(rate))}\"\n",
        "\n",
        "\n",
        "def make_chunks(input_text, language):\n",
        "    language=\"English\"\n",
        "    if language == \"English\":\n",
        "      temp_list = input_text.strip().split(\".\")\n",
        "      filtered_list = [element.strip() + '.' for element in temp_list[:-1] if element.strip() and element.strip() != \"'\" and element.strip() != '\"']\n",
        "      if temp_list[-1].strip():\n",
        "          filtered_list.append(temp_list[-1].strip())\n",
        "      return filtered_list\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import re\n",
        "import uuid\n",
        "def tts_file_name(text):\n",
        "    if text.endswith(\".\"):\n",
        "        text = text[:-1]\n",
        "    text = text.lower()\n",
        "    text = text.strip()\n",
        "    text = text.replace(\" \",\"_\")\n",
        "    truncated_text = text[:25] if len(text) > 25 else text if len(text) > 0 else \"empty\"\n",
        "    random_string = uuid.uuid4().hex[:8].upper()\n",
        "    file_name = f\"/content/edge_tts_voice/{truncated_text}_{random_string}.mp3\"\n",
        "    return file_name\n",
        "\n",
        "\n",
        "from pydub import AudioSegment\n",
        "import shutil\n",
        "import os\n",
        "def merge_audio_files(audio_paths, output_path):\n",
        "    # Initialize an empty AudioSegment\n",
        "    merged_audio = AudioSegment.silent(duration=0)\n",
        "\n",
        "    # Iterate through each audio file path\n",
        "    for audio_path in audio_paths:\n",
        "        # Load the audio file using Pydub\n",
        "        audio = AudioSegment.from_file(audio_path)\n",
        "\n",
        "        # Append the current audio file to the merged_audio\n",
        "        merged_audio += audio\n",
        "\n",
        "    # Export the merged audio to the specified output path\n",
        "    merged_audio.export(output_path, format=\"mp3\")\n",
        "\n",
        "def edge_free_tts(chunks_list,speed,voice_name,save_path):\n",
        "  print(chunks_list)\n",
        "  if len(chunks_list)>1:\n",
        "    chunk_audio_list=[]\n",
        "    if os.path.exists(\"/content/edge_tts_voice\"):\n",
        "      shutil.rmtree(\"/content/edge_tts_voice\")\n",
        "    os.mkdir(\"/content/edge_tts_voice\")\n",
        "    k=1\n",
        "    for i in chunks_list:\n",
        "      print(i)\n",
        "      edge_command=f'edge-tts  --rate={calculate_rate_string(speed)}% --voice {voice_name} --text \"{i}\" --write-media /content/edge_tts_voice/{k}.mp3'\n",
        "      print(edge_command)\n",
        "      var1=os.system(edge_command)\n",
        "      if var1==0:\n",
        "        pass\n",
        "      else:\n",
        "        print(f\"Failed: {i}\")\n",
        "      chunk_audio_list.append(f\"/content/edge_tts_voice/{k}.mp3\")\n",
        "      k+=1\n",
        "    print(chunk_audio_list)\n",
        "    merge_audio_files(chunk_audio_list, save_path)\n",
        "  else:\n",
        "    edge_command=f'edge-tts  --rate={calculate_rate_string(speed)}% --voice {voice_name} --text \"{chunks_list[0]}\" --write-media {save_path}'\n",
        "    print(edge_command)\n",
        "    var2=os.system(edge_command)\n",
        "    if var2==0:\n",
        "      pass\n",
        "    else:\n",
        "      print(f\"Failed: {chunks_list[0]}\")\n",
        "  return save_path\n",
        "\n",
        "\n",
        "text = 'This is Moondream Demo'  # @param {type: \"string\"}\n",
        "Language = \"English\" # @param ['English']\n",
        "\n",
        "Gender = \"Female\"# @param ['Male', 'Female']\n",
        "female_voice=\"en-US-AriaNeural\"# @param[\"en-US-AriaNeural\",'zh-CN-XiaoxiaoNeural','zh-CN-XiaoyiNeural']\n",
        "speed = 1  # @param {type: \"number\"}\n",
        "translate_text_flag  = False\n",
        "long_sentence = False # @param {type:\"boolean\"}\n",
        "save_path = '/content/edge.wav'  # @param {type: \"string\"}\n",
        "if len(save_path)==0:\n",
        "  save_path=tts_file_name(text)\n",
        "if Language == \"English\" :\n",
        "  if Gender==\"Male\":\n",
        "    voice_name=\"en-US-ChristopherNeural\"\n",
        "  if Gender==\"Female\":\n",
        "    voice_name=female_voice\n",
        "    # voice_name=\"en-US-AriaNeural\"\n",
        "\n",
        "\n",
        "if translate_text_flag:\n",
        "  input_text=text\n",
        "  # input_text=translate_text(text, Language)\n",
        "  # print(\"Translateting\")\n",
        "else:\n",
        "  input_text=text\n",
        "if long_sentence==True and translate_text_flag==True:\n",
        "  chunks_list=make_chunks(input_text,Language)\n",
        "elif long_sentence==True and translate_text_flag==False:\n",
        "  chunks_list=make_chunks(input_text,\"English\")\n",
        "else:\n",
        "  chunks_list=[input_text]\n",
        "# print(chunks_list)\n",
        "# edge_save_path=edge_free_tts(chunks_list,speed,voice_name,save_path)\n",
        "# from IPython.display import clear_output\n",
        "# clear_output()\n",
        "# from IPython.display import Audio\n",
        "# Audio(edge_save_path, autoplay=True)\n",
        "\n",
        "from IPython.display import clear_output\n",
        "from IPython.display import Audio\n",
        "if not os.path.exists(\"/content/audio\"):\n",
        "    os.mkdir(\"/content/audio\")\n",
        "import uuid\n",
        "def random_audio_name_generate():\n",
        "  random_uuid = uuid.uuid4()\n",
        "  audio_extension = \".mp3\"\n",
        "  random_audio_name = str(random_uuid)[:8] + audio_extension\n",
        "  return random_audio_name\n",
        "def talk(input_text):\n",
        "  global long_sentence,translate_text_flag,Language,speed,voice_name\n",
        "  if long_sentence==True and translate_text_flag==True:\n",
        "    chunks_list=make_chunks(input_text,Language)\n",
        "  elif long_sentence==True and translate_text_flag==False:\n",
        "    chunks_list=make_chunks(input_text,\"English\")\n",
        "  else:\n",
        "    chunks_list=[input_text]\n",
        "  save_path=\"/content/audio/\"+random_audio_name_generate()\n",
        "  edge_save_path=edge_free_tts(chunks_list,speed,voice_name,save_path)\n",
        "  return edge_save_path\n",
        "\n",
        "\n",
        "edge_save_path=talk(text)\n",
        "Audio(edge_save_path, autoplay=True)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "nQutAlv3HHSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Downlod and Config MoonDream\n",
        "import torch\n",
        "import re\n",
        "import time\n",
        "# from moondream.moondream import detect_device, LATEST_REVISION\n",
        "from threading import Thread\n",
        "from transformers import TextIteratorStreamer, AutoTokenizer, AutoModelForCausalLM\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    use_cpu=False\n",
        "else:\n",
        "    use_cpu=True\n",
        "# Specify whether to use CPU or GPU\n",
        "# use_cpu = True  # Change to True if you want to use CPU\n",
        "\n",
        "if use_cpu:\n",
        "  device = torch.device(\"cpu\")\n",
        "  dtype = torch.float32\n",
        "else:\n",
        "  device=torch.device(\"cuda\")\n",
        "  dtype=torch.float16\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "revision = \"2024-03-13\"\n",
        "model_id = \"vikhyatk/moondream2\"\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_id, revision=LATEST_REVISION)\n",
        "# moondream = AutoModelForCausalLM.from_pretrained(\n",
        "#     model_id, trust_remote_code=True, revision=LATEST_REVISION\n",
        "# ).to(device=device, dtype=dtype)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, revision=revision)\n",
        "\n",
        "moondream = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id, trust_remote_code=True, revision=revision\n",
        ").to(device=device, dtype=dtype)\n",
        "moondream.eval()\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "r37gqp7JcI9n",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title utils for graido\n",
        "def answer_question(image, prompt):\n",
        "    image_embeds = moondream.encode_image(image)\n",
        "    streamer = TextIteratorStreamer(tokenizer, skip_special_tokens=True)\n",
        "    thread = Thread(\n",
        "        target=moondream.answer_question,\n",
        "        kwargs={\n",
        "            \"image_embeds\": image_embeds,\n",
        "            \"question\": prompt,\n",
        "            \"tokenizer\": tokenizer,\n",
        "            \"streamer\": streamer,\n",
        "        },\n",
        "    )\n",
        "    thread.start()\n",
        "\n",
        "    buffer = \"\"\n",
        "    for new_text in streamer:\n",
        "        clean_text = re.sub(\"<$|END$\", \"\", new_text)\n",
        "        buffer += clean_text\n",
        "        yield buffer.strip(\"<END\")\n",
        "def get_answer(prompt,image):\n",
        "  answer = []\n",
        "  for text in answer_question(image, prompt):\n",
        "      answer.append(text)\n",
        "\n",
        "  if len(answer) == 0:\n",
        "      answer.append(\"Nothing Found\")\n",
        "\n",
        "  return answer[-1]\n",
        "import uuid\n",
        "def random_image_name():\n",
        "  random_uuid = uuid.uuid4()\n",
        "  image_extension = \".jpg\"\n",
        "  random_image_name = str(random_uuid)[:8] + image_extension\n",
        "  return random_image_name\n",
        "import shutil\n",
        "import os\n",
        "import uuid\n",
        "from PIL import Image\n",
        "\n",
        "if not os.path.exists(\"/content/upload\"):\n",
        "    os.mkdir(\"/content/upload\")\n",
        "\n",
        "def process_upload_image(prompt, gradio_image):\n",
        "    print(gradio_image)\n",
        "    print(type(gradio_image))\n",
        "    try:\n",
        "        # Handle PIL format image\n",
        "        image = Image.open(gradio_image)\n",
        "        # Generate a random image name using UUID\n",
        "        image_name = random_image_name()\n",
        "        # Save the image to the upload directory\n",
        "        copy_image_path = os.path.join(\"/content/upload\", image_name)\n",
        "        print(f\"Upload Image Saved at {copy_image_path}\")\n",
        "        image.save(copy_image_path)\n",
        "        answer=get_answer(prompt,image)\n",
        "        edge_save_path=talk(answer)\n",
        "        return edge_save_path\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        copy_image_path=f\"/content/upload/{random_image_name()}\"\n",
        "        gradio_image.save(copy_image_path)\n",
        "        print(f\"Upload Image Saved at {copy_image_path}\")\n",
        "        answer=get_answer(prompt,gradio_image)\n",
        "        edge_save_path=talk(answer)\n",
        "        return edge_save_path\n",
        "\n",
        "# # Example usage:\n",
        "# gradio_image_path = \"/content/monalisa.jpg\"  # Replace with the actual path to your image\n",
        "# prompt = \"What's going on? Respond with a single sentence.\"\n",
        "# process_upload_image(prompt, gradio_image_path)\n",
        "# gradio_image_path = Image.open(\"/content/monalisa.jpg\")\n",
        "# process_upload_image(prompt, gradio_image_path)"
      ],
      "metadata": {
        "id": "Ah4V-OqbgDfS",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run Gradio app and copy the url\n",
        "\n",
        "import gradio as gr\n",
        "image_inputs=[gr.Textbox(label=\"Write Prompt\",value=\"What's going on? Respond with a single sentence.\"),gr.Image(type='pil',label=\"Upload a Image\")]\n",
        "# image_outputs=[gr.Textbox(label=\"Result\")]\n",
        "image_outputs=[gr.File(label=\"Result\")]\n",
        "\n",
        "app_demo = gr.Interface(fn=process_upload_image, inputs=image_inputs,outputs=image_outputs , title=\"MoonDream\")\n",
        "app_demo.launch(share=True,debug=True)"
      ],
      "metadata": {
        "id": "3bXnGwosiSAf",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}